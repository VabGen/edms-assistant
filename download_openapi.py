# download_openapi.py
import httpx
import json
import subprocess
import sys
import logging
import re

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def download_openapi_spec(url: str, output_file: str) -> bool:
    """
    Downloads the OpenAPI specification from the given URL and saves it to a file.

    Args:
        url: The URL of the OpenAPI spec (e.g., from Java backend).
        output_file: The path to save the downloaded JSON spec.

    Returns:
        True if successful, False otherwise.
    """
    logger.info(f"Downloading OpenAPI spec from {url}...")
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url)
            response.raise_for_status()

            if "application/json" in response.headers.get("content-type", ""):
                spec_data = response.json()
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(spec_data, f, ensure_ascii=False, indent=2)
                logger.info(
                    f"OpenAPI spec successfully downloaded and saved to {output_file}"
                )
                return True
            else:
                logger.error(
                    f"Error: Response is not JSON. Content-Type: {response.headers.get('content-type')}"
                )
                return False
        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error occurred: {e}")
            return False
        except httpx.RequestError as e:
            logger.error(f"Request error occurred: {e}")
            return False
        except Exception as e:
            logger.error(f"An error occurred during download: {e}")
            return False


def run_datamodel_codegen(input_file: str, output_file: str) -> bool:
    """
    Runs datamodel-codegen to generate Pydantic models from the OpenAPI spec.

    Args:
        input_file: Path to the OpenAPI JSON spec file.
        output_file: Path where the generated Python models will be saved.

    Returns:
        True if successful, False otherwise.
    """
    logger.info(f"Running datamodel-codegen on {input_file}...")
    cmd = [
        sys.executable,
        "-m",
        "datamodel_code_generator",
        "--input",
        input_file,
        "--output",
        output_file,
        "--encoding",
        "utf-8",
        "--use-unique-items-as-set",
        "--target-python-version",
        "3.13",
        "--use-annotated",
        "--use-union-operator",
        "--reuse-model",
        "--use-standard-collections",
        "--use-schema-description",
        "--collapse-root-models",
    ]

    try:
        result = subprocess.run(
            cmd, check=True, capture_output=True, text=True, encoding="utf-8"
        )
        logger.info("datamodel-code-generator executed successfully.")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"datamodel-code-generator failed with return code {e.returncode}")
        logger.error(f"STDOUT: {e.stdout}")
        logger.error(f"STDERR: {e.stderr}")
        return False
    except FileNotFoundError:
        logger.error(
            "Error: 'datamodel-code-generator' is not installed in the current environment."
        )
        return False
    except Exception as e:
        logger.error(f"An error occurred while running datamodel-code-generator: {e}")
        return False


def fix_generated_file(file_path: str):
    """
    Applies necessary fixes to the generated Pydantic models file.

    This function performs post-processing on the file generated by datamodel-codegen
    to address potential issues or adapt the models to specific requirements (e.g., Python 3.13).
    """
    logger.info(f"Applying fixes to {file_path}...")
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # --- Сохраняем импорты __future__, комментарии "generated", и импорты pydantic ---
    future_import_pattern = r"(from __future__ import [^\n]+\n(?:\s*#[^\n]*\n)*)"
    future_match = re.search(future_import_pattern, content)
    future_block = future_match.group(1) if future_match else ""
    if future_match:
        content = content.replace(future_block, "", 1)

    generated_comment_pattern = r"#[^\n]*generated[^\n]*\n(?:#[^\n]*\n)*"
    generated_comment_match = re.search(generated_comment_pattern, content)
    generated_comment_block = (
        generated_comment_match.group(0) if generated_comment_match else ""
    )
    if generated_comment_match:
        content = content.replace(generated_comment_block, "", 1)

    pydantic_import_pattern = r"from pydantic import [^\n]+\n"
    pydantic_import_matches = re.findall(pydantic_import_pattern, content)

    needed_pydantic_items = set()
    for match in pydantic_import_matches:
        content = content.replace(match, "", 1)  # Удаляем старые импорты

    for match in pydantic_import_matches:
        items_str = match.replace("from pydantic import ", "").replace("\n", "")
        items = [item.strip() for item in items_str.split(",")]
        for item in items:
            item_clean = item.strip()
            if item_clean and item_clean != "RootModel":
                needed_pydantic_items.add(item_clean)

    # Проверяем, нужны ли RootModel
    has_root_classes_in_original = "__root__:" in content or bool(
        re.search(
            r"class\s+\w+\s*\(\s*BaseModel\s*\)\s*:\s*\n\s*__root__\s*:\s*", content
        )
    )
    if has_root_classes_in_original or any(
        "RootModel" in imp for imp in pydantic_import_matches
    ):
        needed_pydantic_items.add("RootModel")

    # Формируем новый импорт pydantic
    pydantic_import_line = ""
    if needed_pydantic_items:
        items_list = sorted(list(needed_pydantic_items))
        pydantic_import_line = f"from pydantic import {', '.join(items_list)}\n"

    # Собираем начало файла
    new_start = ""
    if future_block:
        new_start += future_block
    if generated_comment_block:
        new_start += generated_comment_block
    if pydantic_import_line:
        new_start += pydantic_import_line

    content = new_start + content

    # --- Применяем специфические исправления ---
    content = re.sub(r",\s*unique_items=True(?=\s*(?:,|\)))", "", content)
    content = re.sub(r"unique_items=True\s*,?", "", content)

    # Исправляем двойные запятые, возникающие после удаления unique_items
    content = re.sub(r",\s*,", ",", content)

    # Исправляем Field(, возникающее после удаления unique_items
    content = re.sub(r"Field\(\s*,", "Field(", content)

    # Заменяем list[UUID] на set[UUID] для полей, где это подразумевалось через uniqueItems
    content = re.sub(
        r"list\[UUID\] \| None = Field\((.*?)\)",
        lambda m: f"set[UUID] | None = Field({m.group(1)})",
        content,
    )
    content = re.sub(
        r"Annotated\[list\[UUID\] \| None,\s*Field\((.*?)\)\]",
        lambda m: f"Annotated[set[UUID] | None, Field({m.group(1)})]",
        content,
    )

    content = re.sub(
        r"class JsonNode\(BaseModel\):\s*\n\s*__root__:\s*Any",
        "class JsonNode(RootModel[Any]):\n    pass",
        content,
    )

    # --- Сохраняем исправленный файл ---
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)
    logger.info(f"All fixes applied to {file_path}.")


async def main():
    """
    Main function orchestrating the DTO generation process:
    1. Download OpenAPI spec.
    2. Generate Pydantic models.
    3. Apply post-generation fixes.
    """

    def check_datamodel_codegen():
        try:
            result = subprocess.run(
                [sys.executable, "-m", "datamodel_code_generator", "--version"],
                capture_output=True,
                text=True,
            )
            logger.info(f"datamodel-codegen version: {result.stdout.strip()}")
        except Exception as e:
            logger.error(
                "datamodel-codegen not found. Install with: uv pip install datamodel-code-generator"
            )
            sys.exit(1)

    OPENAPI_URL = "http://127.0.0.1:8098/public-resources/openapi"
    SPEC_FILE = "openapi_spec.json"
    DTO_FILE = "src/edms_assistant/infrastructure/resources_openapi.py"

    download_success = await download_openapi_spec(OPENAPI_URL, SPEC_FILE)
    if not download_success:
        logger.error("Download failed. Stopping process.")
        return

    generation_success = run_datamodel_codegen(SPEC_FILE, DTO_FILE)
    if not generation_success:
        logger.error("Model generation failed.")
        sys.exit(1)

    fix_generated_file(DTO_FILE)

    logger.info(
        "OpenAPI spec downloaded, Pydantic models generated, and fixes applied successfully!"
    )


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
