import json
import logging
from typing import List, Dict
from langchain_openai import ChatOpenAI
from edms_assistant.core.settings import settings

logger = logging.getLogger(__name__)

async def route_question_to_file(
    question: str,
    chat_history: List[Dict],
    available_files: List[str]
) -> str:
    if not available_files:
        raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    if len(available_files) == 1:
        return available_files[0]

    llm = ChatOpenAI(
        api_key="not-needed",
        base_url=str(settings.vllm.generative_base_url),
        model=settings.vllm.generative_model,
        temperature=0.0
    )

    prompt = f"""
–¢—ã ‚Äî –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç–∞.
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã: {available_files}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{question}"
–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞: {chat_history}

–í—ã–±–µ—Ä–∏ –û–î–ò–ù —Ñ–∞–π–ª, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –æ—Ç–≤–µ—Ç.
–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "filename": "–∏–º—è_—Ñ–∞–π–ª–∞",
  "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
}}
"""

    try:
        response = await llm.ainvoke([("user", prompt)])
        result = json.loads(response.content)
        filename = result.get("filename", "").strip()
        if filename in available_files:
            logger.info(f"üîç –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è: '{question}' ‚Üí {filename}")
            return filename
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏, –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª: {e}")

    return available_files[0]