import logging
from typing import List, Dict, Any
from pathlib import Path
import pickle

from langchain_openai import ChatOpenAI
from edms_assistant.core.settings import settings
from src.edms_assistant.rag.hybrid_search import HybridSearch

logger = logging.getLogger(__name__)


async def _expand_and_route_query(question: str, chat_history: List[Dict]) -> str:
    """
    –†–∞—Å—à–∏—Ä—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å —É—á—ë—Ç–æ–º:
    - –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞,
    - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ –°–≠–î –∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤,
    - —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ —Ä–æ–¥–æ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π.

    –¶–µ–ª—å: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å recall –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.
    """
    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    history = " ".join(
        msg["content"] for msg in chat_history[-2:] if msg["role"] == "user"
    ) if chat_history else ""

    input_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {history}\n–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {question}" if history else question

    llm = ChatOpenAI(
        api_key="not-needed",
        base_url=str(settings.vllm.generative_base_url),
        model=settings.vllm.generative_model,
        temperature=0.1,  # –ù–µ–º–Ω–æ–≥–æ –∫—Ä–µ–∞—Ç–∏–≤–∞ –¥–ª—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        max_tokens=128
    )

    # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
    system_prompt = (
        "–¢—ã ‚Äî –º–æ–¥—É–ª—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç–∞ (–°–≠–î). "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å –≤ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, "
        "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏. "
        "–£—á–∏—Ç—ã–≤–∞–π –≤—Å–µ —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –ø—Ä–∏–∫–∞–∑—ã, —Ñ–æ—Ä–º—ã, —Ç–∞–±–ª–∏—Ü—ã, PDF-—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏."
    )

    user_prompt = f"""–ü—Ä–∞–≤–∏–ª–∞:
1. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Å–º—ã—Å–ª –≤–æ–ø—Ä–æ—Å–∞.
2. –î–æ–±–∞–≤—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–±—É–º–∞–≥–∞¬ª ‚Üí ¬´–¥–æ–∫—É–º–µ–Ω—Ç¬ª, ¬´–ø–æ–¥–ø–∏—Å–∞—Ç—å¬ª ‚Üí ¬´–≤–∏–∑–∏—Ä–æ–≤–∞—Ç—å¬ª, ¬´—Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å¬ª ‚Üí ¬´–ø—Ä–æ–π—Ç–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ¬ª).
3. –í–∫–ª—é—á–∏ —Å–∏–Ω–æ–Ω–∏–º—ã, —Ä–æ–¥–æ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞.
4. –î–ª—è —Ç–∞–±–ª–∏—Ü: –¥–æ–±–∞–≤—å ¬´—Ç–∞–±–ª–∏—Ü–∞¬ª, ¬´—Å–≤–æ–¥–∫–∞¬ª, ¬´–ø–µ—Ä–µ—á–µ–Ω—å¬ª.
5. –£–¥–∞–ª–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø—Ä–∞–≤—å –æ–ø–µ—á–∞—Ç–∫–∏.
6. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ö–û–†–û–¢–ö–û, –ë–ï–ó –ø–æ—è—Å–Ω–µ–Ω–∏–π ‚Äî —Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.

–ü—Ä–∏–º–µ—Ä—ã:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–ø—É—Å–∫?
–ó–∞–ø—Ä–æ—Å: –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞—è–≤–ª–µ–Ω–∏—è –Ω–∞ –µ–∂–µ–≥–æ–¥–Ω—ã–π –æ–ø–ª–∞—á–∏–≤–∞–µ–º—ã–π –æ—Ç–ø—É—Å–∫, –ø—Ä–∏–∫–∞–∑ –æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –æ—Ç–ø—É—Å–∫–∞

–í–æ–ø—Ä–æ—Å: –ì–¥–µ –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö?
–ó–∞–ø—Ä–æ—Å: —Ç–∞–±–ª–∏—Ü–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ª–∏—Ü, –ø–µ—Ä–µ—á–µ–Ω—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–æ–ª—è–º–∏, —Ä–µ–µ—Å—Ç—Ä –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö

–í–æ–ø—Ä–æ—Å: {input_text}
–ó–∞–ø—Ä–æ—Å:"""

    resp = await llm.ainvoke([
        ("system", system_prompt),
        ("user", user_prompt)
    ])
    return resp.content.strip()


async def retrieve_and_generate(
        question: str,
        filename: str,
        chat_history: List[Dict[str, Any]],
        vector_store
) -> str:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    1. –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞,
    2. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (—Å–µ–º–∞–Ω—Ç–∏–∫–∞ + –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞),
    3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: —Ç–µ–∫—Å—Ç, —Ç–∞–±–ª–∏—Ü—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã.
    """
    logger.debug(f"üí¨ –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ (–∏–∑ Redis): {chat_history}")

    # –®–∞–≥ 1: –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
    enriched_query = await _expand_and_route_query(question, chat_history)
    logger.debug(f"üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {enriched_query}")

    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º —á–∞–Ω–∫–∏ –∏–∑ –¥–∏—Å–∫–∞
    store_dir = Path(settings.paths.vector_stores_dir) / Path(filename).stem
    chunks_path = store_dir / "chunks.pkl"

    if not chunks_path.exists():
        logger.error(f"‚ùå –ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {chunks_path}")
        return "REFLECT: –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω"

    with open(chunks_path, "rb") as f:
        chunks = pickle.load(f)

    # –®–∞–≥ 3: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
    hybrid = HybridSearch(vector_store, chunks)
    results = hybrid.search(query=enriched_query, k=5)
    relevant_docs = [doc for doc, _ in results[:3]] if results else []

    if not relevant_docs:
        return "REFLECT: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

    # –®–∞–≥ 4: –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    context_parts = []
    for doc in relevant_docs:
        source = doc.metadata.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
        doc_type = doc.metadata.get('type', 'text')

        if doc_type == 'table':
            content = f"–¢–ê–ë–õ–ò–¶–ê –∏–∑ {source}:\n{doc.page_content}"
        else:
            content = f"–î–û–ö–£–ú–ï–ù–¢ {source}:\n{doc.page_content}"

        context_parts.append(content)

    context = "\n\n---\n\n".join(context_parts)
    logger.debug(f"üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}")

    # –®–∞–≥ 5: –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
    history_str = "\n".join(
        f"[{m['role'].upper()}]: {m['content']}" for m in chat_history
    ) if chat_history else "–ò—Å—Ç–æ—Ä–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."

    # –®–∞–≥ 6: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ‚Äî —Å—Ç—Ä–æ–≥–∞—è —Ä–æ–ª—å –¥–ª—è LLM
    system_prompt = f"""–¢—ã ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏. 
–¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∞–º–∏, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏, –ø—Ä–∏–∫–∞–∑–∞–º–∏, —Ñ–æ—Ä–º–∞–º–∏, —Ç–∞–±–ª–∏—Ü–∞–º–∏ (Excel), PDF-—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º–∏.

–°—Ç—Ä–æ–≥–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞:
1. –û—Ç–≤–µ—á–∞–π –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ö–û–ù–¢–ï–ö–°–¢–ê –Ω–∏–∂–µ.
2. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è, –ù–ï –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π, –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π.
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –æ—Ç–≤–µ—Ç—å –¢–û–ß–ù–û: ¬´–Ø –Ω–µ –Ω–∞—à—ë–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö¬ª.
4. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏¬ª.
5. –î–ª—è —Ç–∞–±–ª–∏—Ü: —Å–æ—Ö—Ä–∞–Ω—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö, –ø–æ—è—Å–Ω—è–π –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
6. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –∏ —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
7. –£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫ (–∏–º—è —Ñ–∞–π–ª–∞) –ø—Ä–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏.
8. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø–æ–ª–Ω–æ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ.

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–¥–æ–∫—É–º–µ–Ω—Ç—ã):
{context}"""

    # –®–∞–≥ 7: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
    user_prompt = f"""–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:
{history_str}

–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
¬´{question}¬ª

–¢–≤–æ–π –æ—Ç–≤–µ—Ç:"""

    # –®–∞–≥ 8: –í—ã–∑–æ–≤ LLM
    llm = ChatOpenAI(
        api_key="not-needed",
        base_url=str(settings.vllm.generative_base_url),
        model=settings.vllm.generative_model,
        temperature=0.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        max_tokens=1024
    )

    resp = await llm.ainvoke([
        ("system", system_prompt),
        ("user", user_prompt)
    ])
    answer = resp.content.strip()

    # –®–∞–≥ 9: –¢–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if answer == "–Ø –Ω–µ –Ω–∞—à—ë–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö":
        return "REFLECT: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

    return answer